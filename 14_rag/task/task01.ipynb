{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 必要なモジュールをインポート\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
    "from IPython.display import display\n",
    "\n",
    "# 環境変数の取得\n",
    "load_dotenv(\"../.env\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"API_KEY\"]\n",
    "\n",
    "# モデル名\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "# Indexの構築\n",
    "documents = SimpleDirectoryReader(\"./data/text\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# Chat Engineの作成\n",
    "llm = OpenAI(model=MODEL_NAME)\n",
    "retriever = index.as_retriever(similarity_top_k=2)\n",
    "chat_engine = CondensePlusContextChatEngine.from_defaults(\n",
    "    retriever=retriever,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# チャットの開始\n",
    "try:\n",
    "    while(True):\n",
    "        message = input(\"メッセージを入力:\")\n",
    "        if message.strip() == \"\":\n",
    "            break\n",
    "        display(f\"質問:{message}\")\n",
    "\n",
    "        # 質問\n",
    "        response = chat_engine.chat(message)\n",
    "\n",
    "        # 回答を表示\n",
    "        print(response)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"処理を中断しました。\")\n",
    "\n",
    "print(\"---ご利用ありがとうございました！---\")"
   ],
   "id": "af0510b2101618a4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
