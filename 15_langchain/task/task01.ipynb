{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 必要なモジュールをインポート\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# ===== Stateクラスの定義 =====\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# ===== グラフの構築 =====\n",
    "def build_graph(model_name: str):\n",
    "    \"\"\"\n",
    "    Web検索に対応したチャットボット用のグラフを作る。\n",
    "\n",
    "    Args:\n",
    "        model_name (str): 使用するOpenAIモデル名\n",
    "\n",
    "    Returns:\n",
    "        StateGraph: 実行可能なグラフ\n",
    "    \"\"\"\n",
    "\n",
    "    # 検索ツールの定義\n",
    "    tool = TavilySearchResults(max_results=2)\n",
    "    tools = [tool]\n",
    "\n",
    "    # グラフの作成\n",
    "    graph_builder = StateGraph(State)\n",
    "\n",
    "    # 言語モデルの定義\n",
    "    llm = ChatOpenAI(model_name=model_name)\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "    # チャットボットノード\n",
    "    def chatbot(state: State):\n",
    "        return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "    # ノード追加\n",
    "    graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "    # ツールノード追加\n",
    "    tool_node = ToolNode(tools)\n",
    "    graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "    # ツール呼び出しの有無で遷移先を決定\n",
    "    graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "\n",
    "    # ツール実行後は再びchatbotへ戻る\n",
    "    graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "    # 開始ノード設定\n",
    "    graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "    # 記憶付きグラフとしてコンパイル\n",
    "    memory = MemorySaver()\n",
    "    graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "# ===== グラフ実行関数 =====\n",
    "def stream_graph_updates(graph, user_input: str):\n",
    "    \"\"\"\n",
    "    グラフを実行して、最後の回答だけ表示する。\n",
    "    \"\"\"\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [(\"user\", user_input)]},\n",
    "        {\"configurable\": {\"thread_id\": \"1\"}},\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "\n",
    "    last_event = None\n",
    "    for event in events:\n",
    "        last_event = event\n",
    "\n",
    "    if last_event:\n",
    "        print(last_event[\"messages\"][-1].content, flush=True)\n",
    "\n",
    "\n",
    "# ===== メイン実行ロジック =====\n",
    "# 環境変数の読み込み\n",
    "load_dotenv(\"../.env\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"API_KEY\"]\n",
    "\n",
    "# モデル名\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "# グラフの作成\n",
    "graph = build_graph(MODEL_NAME)\n",
    "\n",
    "# メインループ\n",
    "try:\n",
    "    while True:\n",
    "        print()\n",
    "        message = input(\"メッセージを入力:\")\n",
    "        if message.strip() == \"\":\n",
    "            break\n",
    "\n",
    "        print(f\"{message}\")\n",
    "\n",
    "        # グラフ実行\n",
    "        stream_graph_updates(graph, message)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"処理を中断しました。\")\n",
    "\n",
    "print(\"---ご利用ありがとうございました！---\")"
   ],
   "id": "2e3bee7631a28b5b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
